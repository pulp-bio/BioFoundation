# @package _global_
tag: EMG_pretrain

gpus: 4
num_nodes: 1
num_workers: 64
batch_size: 128
max_epochs: 50

final_validate: False
final_test: False

pretrained_checkpoint_path: null
io:
  base_output_path: "/users/mfasulo/BioFoundation/outputs/EMG_pretrain"
  checkpoint_dirpath: ${env:CHECKPOINT_DIR}/checkpoints
  version: 0

defaults:
  - override /data_module: emg_pretrain_data_module
  - override /model: EMG_pretrain
  - override /scheduler: cosine
  - override /task: pretrain_task_EMG
  - override /criterion: pretrain_criterion

masking:
  patch_size: [1, 20]
  masking_ratio: 0.50
  unmasked_loss_coeff: 0.1

input_normalization:
  normalize: True

scheduler:
  trainer: ${trainer}
  min_lr: 1e-6
  warmup_lr_init: 1e-6
  warmup_epochs: 10
  total_training_opt_steps: ${max_epochs}
  t_in_epochs: True

trainer:
  accelerator: gpu
  log_every_n_steps: 25
  num_nodes: ${num_nodes}
  devices: ${gpus}
  strategy: auto
  max_epochs: ${max_epochs}
  gradient_clip_val: 3
  accumulate_grad_batches: 8

model_checkpoint:
  save_last: True
  monitor: "val_loss"
  mode: "min"
  save_top_k: 1

optimizer:
  optim: 'AdamW'
  lr: 1e-4
  betas: [0.9, 0.98]
  weight_decay: 0.01